<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Krasen Samardzhiev, Barbara Metzler, Martin Fleischmann, Dani Arribas-Bel">

<title>Reference Data Selection – Technical notes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300..800;1,300..800&amp;display=swap" rel="stylesheet">


<link rel="stylesheet" href="../styles.css">
<link rel="stylesheet" href="styles.css">
</head>

<body>

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#executive-summary" id="toc-executive-summary" class="nav-link active" data-scroll-target="#executive-summary">Executive summary</a></li>
  <li><a href="#moprhological-data" id="toc-moprhological-data" class="nav-link" data-scroll-target="#moprhological-data">Moprhological data</a>
  <ul class="collapse">
  <li><a href="#ground-truth-classification" id="toc-ground-truth-classification" class="nav-link" data-scroll-target="#ground-truth-classification">Ground truth classification</a></li>
  <li><a href="#building-footprints" id="toc-building-footprints" class="nav-link" data-scroll-target="#building-footprints">Building footprints</a>
  <ul class="collapse">
  <li><a href="#available-sources" id="toc-available-sources" class="nav-link" data-scroll-target="#available-sources">Available sources</a></li>
  <li><a href="#microsoft-building-footprints" id="toc-microsoft-building-footprints" class="nav-link" data-scroll-target="#microsoft-building-footprints">Microsoft building footprints</a></li>
  </ul></li>
  <li><a href="#street-data" id="toc-street-data" class="nav-link" data-scroll-target="#street-data">Street data</a>
  <ul class="collapse">
  <li><a href="#overture-transportation-layer" id="toc-overture-transportation-layer" class="nav-link" data-scroll-target="#overture-transportation-layer">Overture transportation layer</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#ai-data" id="toc-ai-data" class="nav-link" data-scroll-target="#ai-data">AI data</a>
  <ul class="collapse">
  <li><a href="#satellite-imagery" id="toc-satellite-imagery" class="nav-link" data-scroll-target="#satellite-imagery">Satellite imagery</a></li>
  <li><a href="#urban-fabric-classes" id="toc-urban-fabric-classes" class="nav-link" data-scroll-target="#urban-fabric-classes">Urban fabric classes</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="data-selection.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Reference Data Selection</h1>
<p class="subtitle lead">Technical Note D3</p>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Krasen Samardzhiev, Barbara Metzler, Martin Fleischmann, Dani Arribas-Bel </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Charles University; The Alan Turing Institute
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
  
    
  </div>
  


</header>


<section id="executive-summary" class="level1">
<h1>Executive summary</h1>
<p>Summary goes here.</p>
</section>
<section id="moprhological-data" class="level1">
<h1>Moprhological data</h1>
<section id="ground-truth-classification" class="level2">
<h2 class="anchored" data-anchor-id="ground-truth-classification">Ground truth classification</h2>
<p>The main aim of this project is to create a predictive model that is capable of classifying urban fabric. To achieve this we need to use existing urban fabric classifications as ground truth data for model training. We have chosen the <span class="citation" data-cites="primus">(<a href="#ref-primus" role="doc-biblioref">Fleischmann and Samardzhiev Forthcoming</a>)</span> classification to act as the ground truth, since it the only avaialbe classification that fully covers our study area and is based on the highest quality data available - building cadastre data from official sources. Since <span class="citation" data-cites="primus">(<a href="#ref-primus" role="doc-biblioref">Fleischmann and Samardzhiev Forthcoming</a>)</span> is upcoming work we describe its methodology and results in detail in this and in the Algorithm Design and Theoretical Basis Description note.</p>
<p><span class="citation" data-cites="primus">(<a href="#ref-primus" role="doc-biblioref">Fleischmann and Samardzhiev Forthcoming</a>)</span> extends the work of <span class="citation" data-cites="fleischmann2022methodological">(<a href="#ref-fleischmann2022methodological" role="doc-biblioref">Fleischmann et al. 2022</a>)</span>, which has been used in numerous subsequent studies and official planning documents <span class="citation" data-cites="calafiore2023inequalities arribas2022spatial samardzhiev2022functional">(<a href="#ref-calafiore2023inequalities" role="doc-biblioref">Calafiore et al. 2023</a>; <a href="#ref-arribas2022spatial" role="doc-biblioref">Arribas-Bel and Fleischmann 2022</a>; <a href="#ref-samardzhiev2022functional" role="doc-biblioref">K. Samardzhiev et al. 2022</a>)</span> . It uses a combination of buildings and streets to generate Enclosed Tessellation Cells (ETCs), which are spatial units that are centred around buildings, and encapsulate the surrouning space that is nearest to them, rather than other buildings. ETCs boundaries are also limited by streets or a preset buffer distance from the centre of the building, which acts as the centre of the ETC. It is from this combination of buildings, streets and space, that the ETC can combine morphological characteristics of both streets, street intersections, buildings and blocks. The next step in <span class="citation" data-cites="primus">Fleischmann and Samardzhiev (<a href="#ref-primus" role="doc-biblioref">Forthcoming</a>)</span> is to measure different characteristics (or chars) of the ETCs. A literature review carried out by (Measuring urban form) suggests that there are around 74 unique ones that take into account the two dimensional nature of the data. <span class="citation" data-cites="fleischmann2022methodological">(<a href="#ref-fleischmann2022methodological" role="doc-biblioref">Fleischmann et al. 2022</a>)</span> use the full array of characters since they dont know a priori which will be the important variables. <span class="citation" data-cites="primus">(<a href="#ref-primus" role="doc-biblioref">Fleischmann and Samardzhiev Forthcoming</a>)</span> uses a subset of 54 and the detailed list of characters is presented in the Algorithm design technical note, since both our method and <span class="citation" data-cites="primus">(<a href="#ref-primus" role="doc-biblioref">Fleischmann and Samardzhiev Forthcoming</a>)</span> share the same characters. The next stage in the <span class="citation" data-cites="primus">(<a href="#ref-primus" role="doc-biblioref">Fleischmann and Samardzhiev Forthcoming</a>)</span> process is applying two clustering algorithms to generate a classification of ETCs into urban Similar to <span class="citation" data-cites="fleischmann2022methodological">(<a href="#ref-fleischmann2022methodological" role="doc-biblioref">Fleischmann et al. 2022</a>)</span> the Primus clustering approach is split into two parts - defining morphotopes and generating a taxonomy of morphotopes based on their similarity.</p>
<p><span class="citation" data-cites="citation">(<a href="#ref-citation" role="doc-biblioref"><strong>citation?</strong></a>)</span> defines morphotopes as the ‘smallest urban localities obtaining distinctive character among their neighbours from their particular combination of characteristics of plan type, building type and land use’. <!--- which paper ?--> Primus follows this defining and operationalises a morphotope as a set of spatially contiguous ETCs with a minimum of 100 elements, where the internal distance calculated based on the morphological characters is on average lower within the set, than to other sets. The morphotopes for every region are calculated in isolation and in parallel. The definition of the subregions guarantess that all elements that are spatially contiguous, or have any spatial leakage effects, i.e.&nbsp;adjacency or being part of the same street segment, are processed together in the same region. Once the morphotopes are deliniated, the mean of the characters of their constituent ETCs are assigned them. Therefore, every morphotope has the same dimensionality as the ETCs that form it.</p>
<p>The second step is the creation of a taxonomy of morphotypes for the whole of Central Europe. This is achieved through the application of non-spatially restrained ward clustering at two stages - one regional and one global. The resulting hierarchy can be cut at different levels depending on the application. For example at low values, there is some regional information still preserved in the hierarchy - morphotopes from one city are merged to identical morphotopes from the same city. Whereas at higher levels, different types of urban fabric, emerge across countries.</p>
<p>The figure below shows a specific cutoff value, which seperates different types of houses; from heterogenous historical urbanised areas; from recent modern urban developments such as apartment blocks and commercial areas; from large industrial areas.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figures/algo_design/prague_600.png" class="nostretch figure-img" height="400"></p>
<figcaption>High-level urban fabrics</figcaption>
</figure>
</div>
<p>More detailed information about the primus methodology is available in the algorithm-design document, as we aim to follow it as closely as possible in this project.</p>
</section>
<section id="building-footprints" class="level2">
<h2 class="anchored" data-anchor-id="building-footprints">Building footprints</h2>
<p>Building footprints are one of the two core elements needed to generate morphometric classifications. Measurements of aspects of buildings provide the bulk of the information about the morphological character of a place. Many characters in the literature <span class="citation" data-cites="fleischmann2021measuring">(<a href="#ref-fleischmann2021measuring" role="doc-biblioref">Fleischmann, Romice, and Porta 2021</a>)</span>, for example the ratio of perimeter shared with other connected buildings, require very high quality building footprints to accurately reflect the reality of the underlying topology. There are numerorous available source of building footprints - official cadastre polygons; volunteer made OpenStreetMap data; Satellite-derived building footprints; or combinations of all of these such as Overture or EUBUCCO. Each of these data sources come with their own drawbacks and advantages.</p>
<section id="available-sources" class="level3">
<h3 class="anchored" data-anchor-id="available-sources">Available sources</h3>
<p>The highest quality available data is from official cadastre building footprints. These provide the ground truth information for official planning and adiminsitrative applications in many countries. However, the data is not always readily available and even when it is, it requires a lot of preprocessing. For example, there is no readily available cadastre data to download for EU countries such as Hungary and Bulgaria. Even though Data on germany is available, it is split across 16 bundesregions, each of which has its own interface and data format. Furthermore, the data is not always comparative between countries reflective of the physical reality - for example in Czechia the official cadastre reflects shared administration in some modernist apartment blocks, rather than the physical structure of the buildings.</p>
<p>Another source is OpenStreetMap map, which is free and open geographical database generated by volunteers. In many cases the cadastre data is processed and put into OpenStreetMap, alongside volunteer contibutions where official data is missing. The issues with open streetmap data are similar to cadastre data where the cadastre data is used as the basis and is even harder to process since the schema used for buildings is more generic. Furthermore, the quality is unequal - for example the data in Germany is very high quality, but in not in other countries like Italy or Bulgaria.</p>
<p>Another available data source is satellite-derived building footprints, which are becoming more widely adopted due to advances in satellite techonolgy and computer vision algorithms. They have sucessfully been used in applications for city boundary delineation, disegregating population and others <span class="citation" data-cites="samardzhiev2023characterising">(<a href="#ref-samardzhiev2023characterising" role="doc-biblioref">K. P. Samardzhiev 2023</a>)</span>. There are multiple sources of global building footprints available - Google building footprints, Microsoft building footprints, ESRI community data, Overture maps, as well as other proprietary data. The advantage of satellite-derived building footprints data is that it is all derived in a consistent manner and covers large geographical areas. However, the quality is generally worse than other sources and the the geometric topology is typically broken.</p>
<p>The newest available data, such as EUBUCCO or OvertureMaps combine differenttypes of other sources. Overture is based off of OpenStreetMap, but adds a hierarchical structure of sources on top of it. The buildings from Openstreetmap are considered the groundtruth and buildings from additional sources such as satellite data are added where there is no openstreetmap data. This means that in general it has the highest number of available buildings. However, it comes with the same issues that OpenStreetMap data has, and it even further exasperates the data heterogeniety issues - in different places different data sources with different charactersitics are merged. Thus, working with the data requires more preprocessing than other resources.</p>
<p>Similarly, EUBUCCO is another data source that combines multiple datasets - official cadastre data and OpenStreetMap. Therefore it as the same advatanges and disadvantages of its core sources. Furthermore, it has missing data issues that stem from the specific fusion approach of these sources. For example, there is a whole missing neighbourhood in central Prague and, in general, it has less buildings than the official cadastre data for the Central European study area.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figures/algo_design/bubenec.png" class="nostretch figure-img" height="400"></p>
<figcaption>Missing data in central Prague</figcaption>
</figure>
</div>
</section>
<section id="microsoft-building-footprints" class="level3">
<h3 class="anchored" data-anchor-id="microsoft-building-footprints">Microsoft building footprints</h3>
<p>In this project, we use the Microsoft building footprints since they fully cover our study area - Poland, Czechia, Germany, Austria, Slovakia (i.e Central Europe). The dataset also has good worldwide coverage - they contain around 1.5 billion building polygons - and the footprints are derived in a consistent way, which ensures scalability of our method to different countries. It should be noted that our approach can also work for other consistently derived building polygons, Google Footprints for example, so long as all the data is generated from the same source.</p>
<p>However, the data does not come without issues. For example, in dense urban centres entire blocks can be delineated as individual buildings. Given that morphology calculations rely on precise local topological relations between neighbours, such as two buildings touching, this problem renders a whole number of possible measurements described in <span class="citation" data-cites="fleischmann2021measuring">(<a href="#ref-fleischmann2021measuring" role="doc-biblioref">Fleischmann, Romice, and Porta 2021</a>)</span> meaningless. Furthermore, this issue affects even simpler calculations such as counting the number of buildings within a radius or topological neighbourhood. Other issues are that computer vision techniques sometimes miss entire buildings or misidentify building boundaries. Therefore, any approach that uses satellite-derived building footprints should be able to account for these three and potentially other problems.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../figures/algo_design/building_comparison.png" class="nostretch figure-img" height="400"></p>
<figcaption>Comparison between MS buildings and cadastre level buildings in central Prague</figcaption>
</figure>
</div>
</section>
</section>
<section id="street-data" class="level2">
<h2 class="anchored" data-anchor-id="street-data">Street data</h2>
<p>Street network data is the other major data source used in numerical morphometric analysis. It is used to identify spatial relationships, deliniate boundaries for other elements and calculate morphological features of the streets themselves, such as length or width. There are numerous sources for street network data, however the major one is OpenStreetMap and its derivate - OvertureMaps.</p>
<section id="overture-transportation-layer" class="level3">
<h3 class="anchored" data-anchor-id="overture-transportation-layer">Overture transportation layer</h3>
<p>The street network used in this study is a direct download from Overture maps, a processed subset of data from OpenStreetMap with some additions. OpenStreetMap has global coverage and high quality data, especially for vechicular roads, on actual physical layouts of the roads, as well as additional information on street type. We use Overture directly due to the fact that its more accessible and easier to process, however the underlying geometry and information of the two data sources is identical.</p>
<p>The types of street segments used in the analysis are limited to the ones listed in Table 1.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th><em>Types of streets</em></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>living_street</td>
</tr>
<tr class="even">
<td>motorway</td>
</tr>
<tr class="odd">
<td>motorway_link</td>
</tr>
<tr class="even">
<td>pedestrian</td>
</tr>
<tr class="odd">
<td>primary</td>
</tr>
<tr class="even">
<td>primary_link</td>
</tr>
<tr class="odd">
<td>residential</td>
</tr>
<tr class="even">
<td>secondary</td>
</tr>
<tr class="odd">
<td>secondary_link</td>
</tr>
<tr class="even">
<td>tertiary</td>
</tr>
<tr class="odd">
<td>tertiary_link</td>
</tr>
<tr class="even">
<td>trunk</td>
</tr>
<tr class="odd">
<td>trunk_link</td>
</tr>
<tr class="even">
<td>unclassified</td>
</tr>
</tbody>
</table>
<p>Another type of segment that is filtered out are tunnels , since the analysis strictly focuses on two dimensions and therefore undergrounds structures adversely affect the calculation of boundaries and characters.</p>
</section>
</section>
</section>
<section id="ai-data" class="level1">
<h1>AI data</h1>
<section id="satellite-imagery" class="level3">
<h3 class="anchored" data-anchor-id="satellite-imagery">Satellite imagery</h3>
<p>We use satellite images as input into the AI model to predict urban fabric. The satellite image data is sourced from the GHS-composite-S2 R2020A dataset <span class="citation" data-cites="corbane2020global">(<a href="#ref-corbane2020global" role="doc-biblioref">Corbane et al. 2020</a>)</span>. This dataset is a global, cloud-free composite derived from Sentinel-2 L1C data, covering the period from January 2017 to December 2018. The composite images have a resolution of 10 meters per pixel and include three visible bands (red, green, and blue), which are well-suited for urban analysis.</p>
<p>Sentinel-2 data is particularly suitable for this application for several reasons: * Coverage: It provides consistent, openly available data for the entire Earth, making it ideal for projects requiring cross-regional comparisons. * Temporal flexibility: The composite includes data from multiple time points, enabling us to analyze urban patterns over time. * Resolution: At 10 meters per pixel, it offers the highest resolution among openly available datasets, sufficient to distinguish urban features at the neighborhood scale. * Model compatibility: Many machine learning models in geospatial AI are pre-trained on Sentinel-2 data, ensuring compatibility with existing methods and facilitating transfer learning.</p>
</section>
<section id="urban-fabric-classes" class="level3">
<h3 class="anchored" data-anchor-id="urban-fabric-classes">Urban fabric classes</h3>
<p>The urban fabric predictions from our AI model are based on labels from the Spatial Signatures Framework <span class="citation" data-cites="arribas2022spatial fleischmann2022geographical">(<a href="#ref-arribas2022spatial" role="doc-biblioref">Arribas-Bel and Fleischmann 2022</a>; <a href="#ref-fleischmann2022geographical" role="doc-biblioref">Fleischmann and Arribas-Bel 2022</a>)</span>. This framework provides a typology of British urban environments, characterized by both form (physical structure) and function (usage). It captures the complexity of urban areas, offering insights into how different spaces look and operate. While our primary interest is in urban fabric classification focused on form — an approach we expect may be simpler since form is visible in imagery — this classification scheme is still under development. Therefore, we currently use the more comprehensive Spatial Signatures Framework as a proxy, as it aligns with the goals of urban characterization in our project.</p>



</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-arribas2022spatial" class="csl-entry" role="listitem">
Arribas-Bel, Daniel, and Martin Fleischmann. 2022. <span>“Spatial Signatures-Understanding (Urban) Spaces Through Form and Function.”</span> <em>Habitat International</em> 128: 102641.
</div>
<div id="ref-calafiore2023inequalities" class="csl-entry" role="listitem">
Calafiore, Alessia, Krasen Samardzhiev, Francisco Rowe, Martin Fleischmann, and Daniel Arribas-Bel. 2023. <span>“Inequalities in Experiencing Urban Functions. An Exploration of Human Digital (Geo-) Footprints.”</span> <em>Environment and Planning B: Urban Analytics and City Science</em>, 23998083231208507.
</div>
<div id="ref-corbane2020global" class="csl-entry" role="listitem">
Corbane, C., P. Politis, P. Kempeneers, D. Simonetti, P. Soille, A. Burger, M. Pesaresi, F. Sabo, V. Syrris, and T. Kemper. 2020. <span>“A Global Cloud Free Pixel- Based Image Composite from <span>Sentinel</span>-2 Data.”</span> <em>Data in Brief</em> 31 (August): 105737. <a href="https://doi.org/10.1016/j.dib.2020.105737">https://doi.org/10.1016/j.dib.2020.105737</a>.
</div>
<div id="ref-fleischmann2022geographical" class="csl-entry" role="listitem">
Fleischmann, Martin, and Daniel Arribas-Bel. 2022. <span>“Geographical Characterisation of British Urban Form and Function Using the Spatial Signatures Framework.”</span> <em>Scientific Data</em> 9 (1): 546.
</div>
<div id="ref-fleischmann2022methodological" class="csl-entry" role="listitem">
Fleischmann, Martin, Alessandra Feliciotti, Ombretta Romice, and Sergio Porta. 2022. <span>“Methodological Foundation of a Numerical Taxonomy of Urban Form.”</span> <em>Environment and Planning B: Urban Analytics and City Science</em> 49 (4): 1283–99.
</div>
<div id="ref-fleischmann2021measuring" class="csl-entry" role="listitem">
Fleischmann, Martin, Ombretta Romice, and Sergio Porta. 2021. <span>“Measuring Urban Form: Overcoming Terminological Inconsistencies for a Quantitative and Comprehensive Morphologic Analysis of Cities.”</span> <em>Environment and Planning B: Urban Analytics and City Science</em> 48 (8): 2133–50.
</div>
<div id="ref-primus" class="csl-entry" role="listitem">
Fleischmann, Martin, and Krasen Samardzhiev. Forthcoming. <span>“Numerical Taxonomy of Urban Fabric in Central Europe,”</span> Forthcoming.
</div>
<div id="ref-samardzhiev2023characterising" class="csl-entry" role="listitem">
Samardzhiev, Krasen Petrov. 2023. <span>“Characterising Urban Processes Using New Forms of Data and Analysis.”</span> PhD thesis, University of Liverpool United Kingdom.
</div>
<div id="ref-samardzhiev2022functional" class="csl-entry" role="listitem">
Samardzhiev, Krasen, Martin Fleischmann, Daniel Arribas-Bel, Alessia Calafiore, and Francisco Rowe. 2022. <span>“Functional Signatures in Great Britain: A Dataset.”</span> <em>Data in Brief</em> 43: 108335.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>